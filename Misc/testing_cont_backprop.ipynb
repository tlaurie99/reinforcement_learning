{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f55b20-3e29-4411-9272-ae8923ac0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import torch\n",
    "import heapq\n",
    "import torch.nn as nn\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.models.torch.misc import SlimFC, AppendBiasLayer, normc_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f96f8e-0063-4341-8028-daa94f2995bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "torch, nn = try_import_torch()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce567a54-0f40-4615-8afe-2296f15b1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCustomTorchModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        ''''''\n",
    "        self.critic_fcnet = TorchFC(obs_space, action_space, 1, model_config, name + \"_critic\")\n",
    "        self.actor_fcnet = TorchFC(obs_space, action_space, action_space.shape[0]*2, model_config, name + \n",
    "                                   \"_actor\")\n",
    "        input_space = obs_space.shape[0]\n",
    "        self.linear_in = torch.nn.Linear(input_space, 128)\n",
    "        self.linear_middle = nn.Linear(128, 128)\n",
    "        self.linear_final = nn.Linear(128, 1)\n",
    "        self.activation = torch.nn.LeakyReLU()\n",
    "        ''''''\n",
    "\n",
    "        ''''''\n",
    "        self.step = 0\n",
    "        self.threshold = 300 # every 300 SGD updates, we will reinitialize a neuron\n",
    "                             # this currently means, every ~2 iterations with 10000, 2000, 30\n",
    "        self.utility_limit = 0.001\n",
    "        self.track_ids = {i: [] for i in range(self.linear_middle.in_features)}\n",
    "        self.utility_middle_in = {i: 0 for i in range(self.linear_middle.in_features)}\n",
    "        self.utility_middle_out = {i: 0 for i in range(self.linear_middle.out_features)}\n",
    "        self.decay_rate = 0.99\n",
    "        ''''''\n",
    "        \n",
    "    def check_dict(self, step, ids, neuron_id):\n",
    "        if step <= self.threshold:\n",
    "            return False\n",
    "        # using the .get of a dict gives the associated value for the key\n",
    "        # so now we have the list of sgd steps that this was marked a \"dead neuron\"\n",
    "        tracked_steps = ids.get(neuron_id, [])\n",
    "        # check the last number of threshold steps to see if any numbers are missing\n",
    "        # i.e. see if it has been consecutively flagged for the threshold\n",
    "        for num in range(step - self.threshold, step):\n",
    "            # if any numbers are missing mark it false\n",
    "            '''###############################################################################\n",
    "            the paper says to only update the utilities and age after calculating the loss\n",
    "            do we have access after the gradients are updated? \n",
    "            I think having a custom callback overriding on_postprocess_trajectory will do this\n",
    "            ###############################################################################'''\n",
    "            if num not in tracked_steps:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def check_neuron(self, neuron_utility, i):\n",
    "        reint_neuron = False\n",
    "        if abs(neuron_utility) <= self.utility_limit:\n",
    "            if i not in self.track_ids:\n",
    "                self.track_ids[i] = []\n",
    "            self.track_ids[i].append(self.step)\n",
    "            # slice the list to only track the last threshold number of sgd updates\n",
    "            if len(self.track_ids[i]) > self.threshold:\n",
    "                self.track_ids[i] = self.track_ids[i][-self.threshold:]\n",
    "            # check the dictionary to see if the tracked neuron (i) has been on the track_ids dict\n",
    "            # for threshold SGD updates, if so flag it for reinitialization\n",
    "        if self.check_dict(self.step, self.track_ids, i):\n",
    "            reint_neuron = True         \n",
    "        return reint_neuron\n",
    "        \n",
    "    def get_utility(self, layer_output):\n",
    "        dict_checked = False\n",
    "        # loop through each neuron in the first layer\n",
    "        for i in range(self.linear_middle.in_features):\n",
    "            weight_summation = 0\n",
    "            for k in range(self.linear_in.out_features):\n",
    "                # get the summed weights of the next layer\n",
    "                weight = self.linear_middle.weight[i, k].item()\n",
    "                weight_summation += weight\n",
    "            prev_utility = self.decay_rate * self.utility_middle_in[i]\n",
    "            # calculate the weighted input for each neuron of the next layer\n",
    "            weighted_output = torch.mean(layer_output[:, i]) * weight_summation\n",
    "            # update utility for each neuron\n",
    "            '''\n",
    "            Do we want to sum over the minibatch or average? -- average makes more sense\n",
    "            to get the average of the contribution of the neuron\n",
    "            '''\n",
    "            self.utility_middle_in[i] = prev_utility + (1 - self.decay_rate) * weighted_output.item()\n",
    "            # if the utility is below the limit then track its id by appending the step to the list\n",
    "            reint_neuron = self.check_neuron(self.utility_middle_in[i], i)\n",
    "            if reint_neuron:\n",
    "                print(f\"neuron {i} with utility: {self.utility_middle_in[i]} needs reinitialized\")\n",
    "        # just curious printing -- what is the value closest to zero?\n",
    "        if self.step % 3_000 == 0:\n",
    "            min_key = min(self.utility_middle_in, key=lambda k: abs(self.utility_middle_in[k]))\n",
    "            min_value = self.utility_middle_in[min_key]\n",
    "            print(f\"Currently, neuron {min_key} has the utility closest to zero: {min_value}\")\n",
    "        return None\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        logits, _ = self.actor_fcnet(input_dict, state, seq_lens)\n",
    "        means, log_stds = torch.chunk(logits, 2, -1)\n",
    "        means_clamped = torch.clamp(means, -1, 1)\n",
    "        log_stds_clamped = torch.clamp(log_stds, -10, 0)\n",
    "        logits = torch.cat((means_clamped, log_stds_clamped), dim=-1)\n",
    "        \n",
    "        obs_in = input_dict['obs_flat']\n",
    "        critic_in = self.linear_in(obs_in)\n",
    "        critic_in_a = self.activation(critic_in)\n",
    "        critic_middle = self.linear_middle(critic_in_a)\n",
    "        critic_middle_a = self.activation(critic_middle)\n",
    "        critic_final = self.linear_final(critic_middle_a)\n",
    "        self.value = self.activation(critic_final)\n",
    "        \n",
    "        # this was key to implement -- we do not want gradients to flow this way \n",
    "        # also was giving straight nans\n",
    "        with torch.no_grad():\n",
    "            self.get_utility(critic_in_a)\n",
    "        \n",
    "        # this will check SGD updates\n",
    "        \n",
    "        # i.e. 10000 batch size / 2000 minibatch = 5 * 30 num_sgd_iter = 150 sgd updates\n",
    "        # however, using self.step will return 153 for the 1st iter due to dummy batch initialization\n",
    "        self.step += 1\n",
    "        return logits, state\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        return self.value.squeeze(-1)\n",
    "ModelCatalog.register_custom_model(\"SimpleCustomTorchModel\", SimpleCustomTorchModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c45a2-6ecb-42c2-a1e8-4e9603295a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "config = PPOConfig().training(\n",
    "    gamma = 0.99,\n",
    "    lambda_ = 0.95,\n",
    "    # kl_coeff = 0.5,\n",
    "    num_sgd_iter = 30,\n",
    "    lr_schedule = [[0, 0.0003], [15_000_000, 0.00025], [30_000_000, 0.0002], [50_000_000, 0.0001]],\n",
    "    vf_loss_coeff = 1.0,\n",
    "    vf_clip_param = 15.0,\n",
    "    clip_param = 0.3,\n",
    "    grad_clip_by ='norm', \n",
    "    train_batch_size = 10_000, \n",
    "    sgd_minibatch_size = 2_000,\n",
    "    grad_clip = 1.0,\n",
    "    model = {'custom_model': 'SimpleCustomTorchModel', 'vf_share_layers': False, \n",
    "           'fcnet_hiddens': [128,128],'fcnet_activation': 'LeakyReLU'},\n",
    ").environment(env='HalfCheetah-v4'\n",
    ").rollouts(\n",
    "num_rollout_workers = 20,\n",
    ").resources(num_gpus = 1\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "num_iterations = 100\n",
    "results = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    result = algo.train()\n",
    "    print(f\"Iteration: {i}, Mean Reward: {result['episode_reward_mean']}\")\n",
    "    results.append(result['episode_reward_mean'])\n",
    "    \n",
    "ray.shutdown()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab60aa-969a-4760-a84d-c0630fedcb34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
