{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f55b20-3e29-4411-9272-ae8923ac0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import math\n",
    "import torch\n",
    "import heapq\n",
    "import torch.nn as nn\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from torch.nn import functional as F, init\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.models.torch.misc import SlimFC, AppendBiasLayer, normc_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f96f8e-0063-4341-8028-daa94f2995bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "torch, nn = try_import_torch()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce567a54-0f40-4615-8afe-2296f15b1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCustomTorchModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        ''''''\n",
    "        self.critic_fcnet = TorchFC(obs_space, action_space, 1, model_config, name + \"_critic\")\n",
    "        self.actor_fcnet = TorchFC(obs_space, action_space, action_space.shape[0]*2, model_config, name + \n",
    "                                   \"_actor\")\n",
    "        input_space = obs_space.shape[0]\n",
    "        self.linear_in = torch.nn.Linear(input_space, 128)\n",
    "        self.linear_middle = nn.Linear(128, 128)\n",
    "        self.linear_final = nn.Linear(128, 1)\n",
    "        self.activation = torch.nn.LeakyReLU()\n",
    "        ''''''\n",
    "\n",
    "        ''''''\n",
    "        self.step = 0\n",
    "        self.threshold = 300 # every 300 SGD updates, we will reinitialize a neuron\n",
    "                             # this currently means, every ~2 iterations with 10000, 2000, 30\n",
    "        self.utility_limit = 0.1\n",
    "        self.track_ids = {i: [] for i in range(self.linear_middle.in_features)}\n",
    "        self.utility_middle_in = {i: 0 for i in range(self.linear_middle.in_features)}\n",
    "        self.utility_middle_out = {i: 0 for i in range(self.linear_middle.out_features)}\n",
    "        self.decay_rate = 0.99\n",
    "        ''''''\n",
    "        \n",
    "    def check_dict(self, step, ids, neuron_id):\n",
    "        '''\n",
    "        Args:\n",
    "            step: the current number of total SGD updates\n",
    "            ids: dict that hast the neuron_ids and list of steps they have been below the limit\n",
    "            neuron_id: id of the neuron interested in\n",
    "        Notes:\n",
    "            -Extract the steps that the neuron has been below the threshold\n",
    "                using the .get() for a dict returns the value associated with the key i.e. the list of\n",
    "                steps that it has been under the limit\n",
    "            -If at any point there is a break where the neuron was above the threshold,\n",
    "                break out of the loop for checking and return False\n",
    "            -If the neuron has been on the list for the threshold number of SGD updates\n",
    "                return True denoting it will be marked for reinitialization\n",
    "        '''\n",
    "        if step <= self.threshold:\n",
    "            return False\n",
    "        tracked_steps = ids.get(neuron_id, [])\n",
    "        for num in range(step - self.threshold, step):\n",
    "            '''###############################################################################\n",
    "            the paper says to only update the utilities and age after calculating the loss\n",
    "            do we have access after the gradients are updated? \n",
    "            I think having a custom callback overriding on_postprocess_trajectory will do this\n",
    "            ###############################################################################'''\n",
    "            if num not in tracked_steps:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def check_neuron(self, neuron_utility, i):\n",
    "        '''\n",
    "        Args:\n",
    "            neuron_utility: the current neuron (i) to check if it needs reinitialized\n",
    "        Notes:\n",
    "            - Checks if the neuron should be reinitialized\n",
    "                i.e. if the neuron is below the threshold limit, add it to a tracked_ids list\n",
    "                and when this crosses a certain X number of SGD updates consecutively, reinitialize it\n",
    "            -Return true if the above is true\n",
    "            -Makes a list within the track_ids dict that will track each step the neuron is below the limit\n",
    "                this list is sliced to prevent it from becoming exponentially large\n",
    "        '''\n",
    "        reint_neuron = False\n",
    "        if abs(neuron_utility) <= self.utility_limit:\n",
    "            if i not in self.track_ids:\n",
    "                self.track_ids[i] = []\n",
    "            self.track_ids[i].append(self.step)\n",
    "            if len(self.track_ids[i]) > self.threshold:\n",
    "                self.track_ids[i] = self.track_ids[i][-self.threshold:]\n",
    "        if self.check_dict(self.step, self.track_ids, i):\n",
    "            reint_neuron = True         \n",
    "        return reint_neuron\n",
    "        \n",
    "    def get_utility(self, layer_output):\n",
    "        '''\n",
    "        Args:\n",
    "            layer_output: layer output of interest that will impace the next layer\n",
    "                this output is after the activation function is applied\n",
    "        Notes:\n",
    "            -Loops through each neuron in layer l (k) and sums the weights going to layer l+1 (i)\n",
    "                where .weight[i, k] is summing the current l layer neurons to the ith neuron of layer l+1\n",
    "            -Calculates the utility metric of the ith neuron in l+1 by using the mean output of the batch\n",
    "            -Add the utility metric for each neuron of the l+1 layer to a dict with the associate ith neuron key\n",
    "            -Checks if the neuron should be reinitialized\n",
    "                i.e. if the neuron is below the threshold limit, add it to a tracked_ids dict\n",
    "                and when this crosses a certain X number of SGD updates consecutively, reinitialize it\n",
    "            -Reinitializes the neuron if the above is true\n",
    "        '''\n",
    "        dict_checked = False\n",
    "        for i in range(self.linear_middle.in_features):\n",
    "            weight_summation = 0\n",
    "            for k in range(self.linear_in.out_features):\n",
    "                weight = self.linear_middle.weight[i, k].item()\n",
    "                weight_summation += weight\n",
    "            prev_utility = self.decay_rate * self.utility_middle_in[i]\n",
    "            weighted_output = torch.mean(layer_output[:, i]) * weight_summation\n",
    "            self.utility_middle_in[i] = prev_utility + (1 - self.decay_rate) * weighted_output.item()\n",
    "            reint_neuron = self.check_neuron(self.utility_middle_in[i], i)\n",
    "            if reint_neuron:\n",
    "                self.reinitialize_neuron(self.linear_in, self.linear_middle, i)\n",
    "        return\n",
    "    \n",
    "    def reinitialize_neuron(self, input_layer, next_layer, i):\n",
    "        '''\n",
    "        Args:\n",
    "            i: neuron that needs initialization\n",
    "            input_layer: the current layer that is of interest\n",
    "            next_layer: the next layer which will be used to set the \n",
    "                weights going to it to zero\n",
    "        Notes:\n",
    "            -Cannot use torch's Xavier / Kaiming reint since it requires 2-D tenors where\n",
    "                we have 1-D (hidden_layer_size, single neuron), so currently using a uniform dist.\n",
    "                -Will look into Xavier for 1-D cases if possible\n",
    "            -Reinitializes weights going to neuron i with the uniform dist.\n",
    "            -Resets weights outgoing from neuron i to zero\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            init.uniform_(input_layer.weight[i, :], a=0, b=1)\n",
    "            print(f\"reinitialized input to neuron {i}\")\n",
    "            next_layer.weight[:, i].fill_(0)\n",
    "            print(f\"set output weights from neuron {i} to zero\")\n",
    "            \n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        logits, _ = self.actor_fcnet(input_dict, state, seq_lens)\n",
    "        means, log_stds = torch.chunk(logits, 2, -1)\n",
    "        means_clamped = torch.clamp(means, -1, 1)\n",
    "        log_stds_clamped = torch.clamp(log_stds, -10, 0)\n",
    "        logits = torch.cat((means_clamped, log_stds_clamped), dim=-1)\n",
    "        \n",
    "        obs_in = input_dict['obs_flat']\n",
    "        critic_in = self.linear_in(obs_in)\n",
    "        critic_in_a = self.activation(critic_in)\n",
    "        critic_middle = self.linear_middle(critic_in_a)\n",
    "        critic_middle_a = self.activation(critic_middle)\n",
    "        critic_final = self.linear_final(critic_middle_a)\n",
    "        self.value = self.activation(critic_final)\n",
    "        \n",
    "        # this was key to implement -- we do not want gradients to flow this way \n",
    "        # also was giving straight nans\n",
    "        with torch.no_grad():\n",
    "            self.get_utility(critic_in_a)\n",
    "        \n",
    "        # this will check SGD updates\n",
    "        \n",
    "        # i.e. 10000 batch size / 2000 minibatch = 5 * 30 num_sgd_iter = 150 sgd updates\n",
    "        # however, using self.step will return 153 for the 1st iter due to dummy batch initialization\n",
    "        self.step += 1\n",
    "        return logits, state\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        return self.value.squeeze(-1)\n",
    "ModelCatalog.register_custom_model(\"SimpleCustomTorchModel\", SimpleCustomTorchModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c45a2-6ecb-42c2-a1e8-4e9603295a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "config = PPOConfig().training(\n",
    "    gamma = 0.99,\n",
    "    lambda_ = 0.95,\n",
    "    # kl_coeff = 0.5,\n",
    "    num_sgd_iter = 30,\n",
    "    lr_schedule = [[0, 0.0003], [15_000_000, 0.00025], [30_000_000, 0.0002], [50_000_000, 0.0001]],\n",
    "    vf_loss_coeff = 1.0,\n",
    "    vf_clip_param = 15.0,\n",
    "    clip_param = 0.3,\n",
    "    grad_clip_by ='norm', \n",
    "    train_batch_size = 10_000, \n",
    "    sgd_minibatch_size = 2_000,\n",
    "    grad_clip = 1.0,\n",
    "    model = {'custom_model': 'SimpleCustomTorchModel', 'vf_share_layers': False, \n",
    "           'fcnet_hiddens': [128,128],'fcnet_activation': 'LeakyReLU'},\n",
    ").environment(env='HalfCheetah-v4'\n",
    ").rollouts(\n",
    "num_rollout_workers = 20,\n",
    ").resources(num_gpus = 1\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "num_iterations = 100\n",
    "results = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    result = algo.train()\n",
    "    print(f\"Iteration: {i}, Mean Reward: {result['episode_reward_mean']}\")\n",
    "    results.append(result['episode_reward_mean'])\n",
    "    \n",
    "ray.shutdown()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab60aa-969a-4760-a84d-c0630fedcb34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
