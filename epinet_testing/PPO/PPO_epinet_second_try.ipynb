{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2099f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray import tune, air\n",
    "from ray.rllib.core.models.configs import MLPHeadConfig\n",
    "from ray.rllib.core.models.catalog import Catalog\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.annotations import OverrideToImplementCustomLogic\n",
    "from gymnasium.spaces import Box\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig\n",
    "import ray.rllib.algorithms.ppo as ppo\n",
    "from ray.rllib.utils.typing import Dict, TensorType, List, ModelConfigDict\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from ray.rllib.models.torch.misc import SlimFC, AppendBiasLayer\n",
    "from ray.rllib.policy.torch_policy import TorchPolicy\n",
    "from ray.rllib.policy.policy_template import build_policy_class\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ray import tune\n",
    "import math\n",
    "from torch.distributions.normal import Normal\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd71ca8",
   "metadata": {},
   "source": [
    "### PPO MoG Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a57a6",
   "metadata": {},
   "source": [
    "### Data flow: obs -> forward() -> model_out \\-> value_function() -> V(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5a4fa-c09c-492e-9968-989b5855cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2954d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch, nn = try_import_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5d111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039b7f6",
   "metadata": {},
   "source": [
    "### MOG and NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736edb5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global adder\n",
    "adder = 1.000001\n",
    "global num_gaussians\n",
    "num_gaussians = 2\n",
    "global parquet_file_name\n",
    "\n",
    "class CustomTorchModelMOG(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super(CustomTorchModelMOG, self).__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        nn.Module.__init__(self)\n",
    "        #get layers from config\n",
    "        hidden_layer0 = model_config['fcnet_hiddens'][0]\n",
    "        hidden_layer1 = model_config['fcnet_hiddens'][1]\n",
    "        enn_layer = 50\n",
    "        #object instance variables\n",
    "        self.std = 1.0\n",
    "        # self.seed = 15546\n",
    "        self.mean = 0.0\n",
    "        self.gamma = 0.99\n",
    "        self.step_number = 0\n",
    "        self.z_indices = None\n",
    "        self.step_cut_off = 200\n",
    "        self.adder = 1.000000001\n",
    "        # random.seed(self.seed)\n",
    "        self.elu = torch.nn.ELU() \n",
    "        # np.random.seed(self.seed)\n",
    "        # torch.manual_seed(self.seed)\n",
    "        self.num_actions = action_space.shape[0]\n",
    "        self.initializer = torch.nn.init.xavier_normal_\n",
    "        self.activation_fn = model_config['fcnet_activation']\n",
    "        self.z_dim = model_config['custom_model_config'].get('z_dim', 5)\n",
    "        self.device = torch.device('cpu')\n",
    "        self.num_gaussians = model_config['custom_model_config'].get('num_gaussians', 3)\n",
    "        self.distribution = Normal(torch.full((self.z_dim,), self.mean), torch.full((self.z_dim,), self.std))\n",
    "        \n",
    "        self.actor_network = TorchFC(obs_space, action_space, action_space.shape[0]*2, model_config, name + \"_actor\")\n",
    "        self.base_in = SlimFC(obs_space.shape[0], hidden_layer0, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.base_1 = SlimFC(hidden_layer0, hidden_layer1, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.base_out = SlimFC(hidden_layer1, self.num_gaussians*3, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.enn_learnable_in = SlimFC(hidden_layer1 + 1, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.enn_learnable_1 = SlimFC(enn_layer, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.enn_learnable_out = SlimFC(enn_layer, 1, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.prior_in = SlimFC(hidden_layer1 + 1, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.prior_1 = SlimFC(enn_layer, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "        self.prior_out = SlimFC(enn_layer, 1, initializer=self.initializer, activation_fn=self.activation_fn).to(self.device)\n",
    "\n",
    "        self.to(self.device)\n",
    "        self.action_space = action_space        \n",
    "        self.actor_fcnet = TorchFC(obs_space, action_space, action_space.shape[0]*2, model_config, name + \"_actor\")   \n",
    "\n",
    "        \n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    @OverrideToImplementCustomLogic\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        # Actor forward pass\n",
    "        raw_action_logits, _ = self.actor_fcnet(input_dict, state, seq_lens)\n",
    "\n",
    "        #critic forward pass\n",
    "        obs = input_dict['obs_flat'].float().to(self.device)\n",
    "        batch_size = obs.shape[0]\n",
    "        \n",
    "        base_1 = self.base_1(self.base_in(obs))\n",
    "        base_1_detached_unsqueeze = torch.unsqueeze(base_1, 1).detach()\n",
    "        base_out = self.base_out(base_1)\n",
    "        base_out_detached = base_out.detach()\n",
    "        \n",
    "        self.z_indices = self.distribution.sample((batch_size,)).to(self.device)\n",
    "        self.z_unsqueeze = torch.unsqueeze(self.z_indices, -1)\n",
    "        enn_input = torch.cat((self.z_unsqueeze, base_1_detached_unsqueeze.expand(-1, self.z_dim, -1)), dim=2)\n",
    "        \n",
    "        if self.step_number < self.step_cut_off:\n",
    "            prior_out = self.prior_out(self.prior_1(self.prior_in(enn_input)))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                prior_out = self.prior_out(self.prior_1(self.prior_in(enn_input)))\n",
    "                \n",
    "        prior_bmm = torch.bmm(torch.transpose(prior_out, 1, 2), self.z_unsqueeze)\n",
    "        prior = prior_bmm.squeeze(-1)\n",
    "        learnable_out = self.enn_learnable_out(self.enn_learnable_1(self.enn_learnable_in(enn_input)))\n",
    "        learnable_bmm = torch.bmm(torch.transpose(learnable_out, 1, 2), self.z_unsqueeze)\n",
    "        learnable = learnable_bmm.squeeze(-1)\n",
    "        self.enn_out = torch.mean(learnable + prior, dim = -1)\n",
    "        \n",
    "        means = base_out_detached[:, :self.num_gaussians]\n",
    "        sigmas = torch.nn.functional.elu(base_out_detached[:, self.num_gaussians:self.num_gaussians*2]) + self.adder\n",
    "        alphas = torch.nn.functional.softmax(base_out_detached[:, self.num_gaussians*2:], dim=-1)\n",
    "\n",
    "        self._u, self._sigmas, self._alphas = means, sigmas, alphas\n",
    "        self.step_number += 1\n",
    "        \n",
    "        return raw_action_logits, state\n",
    "\n",
    "    @OverrideToImplementCustomLogic\n",
    "    def value_function(self):\n",
    "        multiply = self._u * self._alphas\n",
    "        self.critic_value = torch.sum(multiply.to(self.device), dim = 1)\n",
    "        self.final_critic_value = self.critic_value.to(self.device) + self.enn_out.to(self.device)\n",
    "        return self.final_critic_value.to(self.device)\n",
    "\n",
    "    def predict_gmm_params(self, observation):\n",
    "        base_in = self.base_out(self.base_1(self.base_in(observation)))\n",
    "        means = base_out[:, :self.num_gaussians]\n",
    "        sigmas_prev = base_out[:, self.num_gaussians:self.num_gaussians*2]\n",
    "        sigmas = self.elu(sigmas_prev) + self.adder\n",
    "        alphas = base_out[:, self.num_gaussians*2:]\n",
    "        \n",
    "        return means, sigmas, alphas\n",
    "    \n",
    "    def compute_log_likelihood(self, td_targets, mu_pred, sigma_pred, alphas_pred):\n",
    "        \n",
    "        td_targets_expanded = td_targets.unsqueeze(1)\n",
    "        \n",
    "        sigma_clamped = torch.clamp(sigma_pred, 1e-9, None)\n",
    "        # alphas_clamped = torch.clamp(alpha_pred, 1e-30, 1e5)\n",
    "        \n",
    "        log_2_pi = torch.log(2*torch.tensor(math.pi))\n",
    "        \n",
    "        mus = td_targets_expanded - mu_pred\n",
    "        \n",
    "        logp = torch.clamp(-torch.log(sigma_clamped) - .5 * log_2_pi - torch.square(mus) / (2*torch.square(sigma_clamped)), -1e9, None)\n",
    "        loga = torch.nn.functional.log_softmax(alphas_pred, dim=-1)\n",
    "\n",
    "        summing_log = -torch.logsumexp(logp + loga, dim=-1)\n",
    "        \n",
    "        return summing_log\n",
    "    \n",
    "    def enn_loss(self, obs, rewards, dones):\n",
    "        # gives the target for the TD loss for the ENN\n",
    "        base_1 = self.base_1(self.base_in(obs))\n",
    "        base_out = self.base_out(base_1)\n",
    "        base_1_detached_unsqueeze = torch.unsqueeze(base_1, 1).detach()\n",
    "        base_out_detached = base_out.detach()\n",
    "        enn_input = torch.cat((self.z_unsqueeze, base_1_detached_unsqueeze.expand(-1, self.z_dim, -1)), dim=2)\n",
    "        \n",
    "        if self.step_number < self.step_cut_off:\n",
    "            prior_out = self.prior_out(self.prior_1(self.prior_in(enn_input)))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                prior_out = self.prior_out(self.prior_1(self.prior_in(enn_input)))\n",
    "                \n",
    "        prior_bmm = torch.bmm(torch.transpose(prior_out, 1, 2), self.z_unsqueeze)\n",
    "        prior = prior_bmm.squeeze(-1)\n",
    "        learnable_out = self.enn_learnable_out(self.enn_learnable_1(self.enn_learnable_in(enn_input)))\n",
    "        learnable_bmm = torch.bmm(torch.transpose(learnable_out, 1, 2), self.z_unsqueeze)\n",
    "        learnable = learnable_bmm.squeeze(-1)\n",
    "        enn_target = torch.mean(learnable + prior, dim = -1)\n",
    "        \n",
    "        means = base_out_detached[:, :self.num_gaussians]\n",
    "        sigmas = torch.nn.functional.elu(base_out_detached[:, self.num_gaussians:self.num_gaussians*2]) + self.adder\n",
    "        alphas = torch.nn.functional.softmax(base_out_detached[:, self.num_gaussians*2:], dim=-1)\n",
    "        next_values = torch.sum(means * alphas, dim = -1) + enn_target\n",
    "        \n",
    "        target = rewards + self.gamma * next_values.clone().detach() * (1 - dones.float())\n",
    "        difference = torch.square(self.final_critic_value - target)\n",
    "        mse = torch.mean(difference)\n",
    "        \n",
    "        return mse\n",
    "\n",
    "\n",
    "    @OverrideToImplementCustomLogic\n",
    "    def custom_loss(self, policy_loss, sample_batch):\n",
    "        gamma = 0.99\n",
    "        cur_obs = sample_batch[SampleBatch.CUR_OBS]\n",
    "        next_states = sample_batch[SampleBatch.NEXT_OBS]\n",
    "        rewards = sample_batch[SampleBatch.REWARDS]\n",
    "        dones = sample_batch[SampleBatch.DONES]\n",
    "        \n",
    "        enn_loss = self.enn_loss(next_states, rewards, dones)\n",
    "\n",
    "        mu_pred, sigma_pred, w_pred = self.predict_gmm_params(cur_obs)\n",
    "        mu_target, sigma_target, w_target = self.predict_gmm_params(next_states)\n",
    "        w_target = torch.nn.functional.softmax(w_target, dim = -1)\n",
    "\n",
    "        \n",
    "        next_state_value = torch.sum(mu_target * w_target, dim = 1).clone().detach()\n",
    "        td_targets = rewards + gamma * next_state_value * (1 - dones.float())\n",
    "        \n",
    "        log_likelihood = self.compute_log_likelihood(td_targets, mu_pred, sigma_pred, w_pred)\n",
    "        log_likelihood = torch.clamp(log_likelihood, -10, 80)\n",
    "        nll_loss = torch.mean(log_likelihood)\n",
    "        \n",
    "        total_loss = [loss + (nll_loss + enn_loss) for loss in policy_loss]\n",
    "        \n",
    "        if self.step_number % 1_000 == 0:\n",
    "            print(f\"policy loss: {policy_loss} enn loss: {enn_loss} nll loss: {nll_loss}\")\n",
    "    \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "ModelCatalog.register_custom_model(\"custom_torch_model_mog\", CustomTorchModelMOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935974d",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "config = PPOConfig().training(\n",
    "    gamma = 0.99,\n",
    "    lambda_ = 0.95,\n",
    "    # kl_coeff = 0.5,\n",
    "    num_sgd_iter = 30,\n",
    "    lr_schedule = [[0, 0.0003], [15_000_000, 0.00025], [30_000_000, 0.0002], [50_000_000, 0.0001]],\n",
    "    vf_loss_coeff = 1.0,\n",
    "    vf_clip_param = 15.0,\n",
    "    clip_param = 0.3,\n",
    "    grad_clip_by ='norm', \n",
    "    train_batch_size = 19_200, \n",
    "    sgd_minibatch_size = 4_096,\n",
    "    grad_clip = 1.0,\n",
    "    model = {'custom_model': 'custom_torch_model_mog', 'vf_share_layers': False, \n",
    "           'fcnet_hiddens': [2048,2048],'fcnet_activation': 'LeakyReLU'},\n",
    ").environment(env='HalfCheetah-v4'\n",
    ")\n",
    "#.callbacks(MyCustomCallback\n",
    "#)\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "num_iterations = 500\n",
    "results = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    result = algo.train()\n",
    "    print(f\"Iteration: {i}, Mean Reward: {result['episode_reward_mean']}\")\n",
    "    results.append(result['episode_reward_mean'])\n",
    "    \n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results)\n",
    "plt.title('Training Progress - Mean Reward per Episode')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Mean Reward')\n",
    "# plt.savefig('MOG and Energy Distance - HalfCheetah-v4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1157d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('training_rewards_enn_2.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Iteration', 'Mean Reward'])  # Writing header of the CSV\n",
    "    for iteration, reward in enumerate(results):\n",
    "        writer.writerow([iteration, reward])  # Writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed46c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV files\n",
    "df1 = pd.read_csv('training_rewards_enn.csv')\n",
    "df2 = pd.read_csv('training_rewards.csv')\n",
    "df3 = pd.read_csv('training_rewards_enn_2.csv')\n",
    "\n",
    "# Create a Plotly graph\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add trace for the first CSV file\n",
    "fig.add_trace(go.Scatter(x=df1['Iteration'], y=df1['Mean Reward'], mode='lines+markers', name='ENN Rewards'))\n",
    "\n",
    "# Add trace for the second CSV file\n",
    "fig.add_trace(go.Scatter(x=df2['Iteration'], y=df2['Mean Reward'], mode='lines+markers', name='Standard Rewards'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df3['Iteration'], y=df3['Mean Reward'], mode='lines+markers', name='ENN Rewards 2'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Training Rewards Comparison',\n",
    "                  xaxis_title='Iteration',\n",
    "                  yaxis_title='Mean Reward')\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025fea2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
