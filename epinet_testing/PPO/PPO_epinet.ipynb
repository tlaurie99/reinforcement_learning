{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6d410-4dab-451c-a904-7f64b15fce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from ray import tune, air\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import ray.rllib.algorithms.ppo as dqn\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.core.models.catalog import Catalog\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.policy.torch_policy import TorchPolicy\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.core.models.configs import MLPHeadConfig\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.misc import SlimFC, AppendBiasLayer\n",
    "from ray.rllib.policy.policy_template import build_policy_class\n",
    "from ray.rllib.algorithms.dqn.dqn_torch_model import DQNTorchModel\n",
    "from ray.rllib.utils.annotations import OverrideToImplementCustomLogic\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.typing import Dict, TensorType, List, ModelConfigDict\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c731a0-994d-4ffe-a802-402036ac4228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch, nn = try_import_torch()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8fc97-8c7b-42a8-b9e8-828f042176c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLL_EpistemicNNModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super(NLL_EpistemicNNModel, self).__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "        #get layers from config\n",
    "        hidden_layer0 = model_config['fcnet_hiddens'][0]\n",
    "        hidden_layer1 = model_config['fcnet_hiddens'][1]\n",
    "        enn_layer = 50\n",
    "        #object instance variables\n",
    "        self.std = 1.0\n",
    "        # self.seed = 15546\n",
    "        self.mean = 0.0\n",
    "        self.gamma = 0.99\n",
    "        self.step_number = 0\n",
    "        self.z_indices = None\n",
    "        self.step_cut_off = 200\n",
    "        self.adder = 1.000000001\n",
    "        # random.seed(self.seed)\n",
    "        self.elu = torch.nn.ELU() \n",
    "        # np.random.seed(self.seed)\n",
    "        # torch.manual_seed(self.seed)\n",
    "        self.num_actions = action_space.shape[0]\n",
    "        self.initializer = torch.nn.init.xavier_normal_\n",
    "        self.activation_fn = model_config['fcnet_activation']\n",
    "        self.z_dim = model_config['custom_model_config'].get('z_dim', 5)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.num_gaussians = model_config['custom_model_config'].get('num_gaussians', 3)\n",
    "        self.distribution = Normal(torch.full((self.z_dim,), self.mean), torch.full((self.z_dim,), self.std))\n",
    "        \n",
    "        self.actor_network = TorchFC(obs_space, action_space, action_space.shape[0]*2, model_config, name + \"_actor\")\n",
    "        self.base_in = SlimFC(obs_space.shape[0], hidden_layer0, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.base_1 = SlimFC(hidden_layer0, hidden_layer1, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.base_out = SlimFC(hidden_layer1, self.num_gaussians*3, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        #enn learnable network\n",
    "        self.enn_learnable_in = SlimFC(hidden_layer1 + 1, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.enn_learnable_1 = SlimFC(enn_layer, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.enn_learnable_out = SlimFC(enn_layer, 1, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        #prior network (learnable for x steps and then static afterwards)\n",
    "        self.prior_in = SlimFC(hidden_layer1 + 1, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.prior_1 = SlimFC(enn_layer, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.prior_out = SlimFC(enn_layer, 1, initializer=self.initializer, activation_fn=self.activation_fn)        \n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict[\"obs_flat\"].float()        \n",
    "        action_logits, _ = self.actor_network(input_dict, state, seq_lens)     \n",
    "        batch_size = obs.shape[0]\n",
    "        \n",
    "        base_in = self.base_in(obs)\n",
    "        base_1 = self.base_1(base_in).to(self.device)\n",
    "        base_1_detached_unsqueeze = torch.unsqueeze(base_1, 1).detach()\n",
    "        base_out = self.base_out(base_1)\n",
    "        base_out_detached = base_out.detach()\n",
    "\n",
    "        self.z_indices = self.distribution.sample((batch_size,)).to(self.device)\n",
    "        self.z_unsqueeze = torch.unsqueeze(self.z_indices, -1)\n",
    "        enn_input = torch.cat((self.z_unsqueeze, base_1_detached_unsqueeze.expand(-1, self.z_dim, -1)), dim=2)\n",
    "\n",
    "        if self.step_number < self.step_cut_off:\n",
    "            #prior value (learnable)\n",
    "            prior_in = self.prior_in(enn_input)\n",
    "            prior_1 = self.prior_1(prior_in)\n",
    "            prior = self.prior_out(prior_1)\n",
    "            # action_logits = torch.normal(mean = 0, std = 1, size=(1, self.num_actions*2)).to(self.device)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #prior value (static)\n",
    "                prior_in = self.prior_in(enn_input)\n",
    "                prior_1 = self.prior_1(prior_in)\n",
    "                prior = self.prior_out(prior_1)\n",
    "                \n",
    "        prior_bmm = torch.bmm(torch.transpose(prior, 1, 2), self.z_unsqueeze)\n",
    "        prior_out = prior_bmm.squeeze(-1)\n",
    "        # learnable on features and z concat\n",
    "        learnable_in = self.enn_learnable_in(enn_input)\n",
    "        learnable_1 = self.enn_learnable_1(learnable_in)\n",
    "        learnable = self.enn_learnable_out(learnable_1)\n",
    "        learnable_bmm = torch.bmm(torch.transpose(learnable, 1, 2), self.z_unsqueeze)\n",
    "        learnable_out = learnable_bmm.squeeze(-1)\n",
    "\n",
    "        # add enn networks together to then add to the weighted average in the value function\n",
    "        self.enn_out = torch.mean(learnable_out + prior_out, dim = -1)\n",
    "        '''\n",
    "        check the squeeze dimensions above as well -- am I losing information?\n",
    "\n",
    "        \n",
    "        this mean helps in the addition process to get a tensor of the batch size out\n",
    "        --> (128, 1, 1) --squeeze--> (128,1) --mean of last dimension--> (128,)\n",
    "        the value function returns the same after summing the mean * alphas --gives--> (128,)\n",
    "        '''\n",
    "        #means\n",
    "        means = base_out_detached[:, :self.num_gaussians]\n",
    "        self._u = means\n",
    "        #sigmas\n",
    "        sigmas = base_out_detached[:, self.num_gaussians:self.num_gaussians*2]\n",
    "        sigmas = self.elu(sigmas) + self.adder\n",
    "        self._sigmas = sigmas\n",
    "        #weights\n",
    "        alphas = base_out_detached[:, self.num_gaussians*2:]\n",
    "        alphas = torch.nn.functional.softmax(alphas, dim=-1)\n",
    "        self._alphas = alphas\n",
    "\n",
    "        self.step_number += 1\n",
    "            \n",
    "            \n",
    "        return action_logits, state\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        multiply = self._u * self._alphas\n",
    "        self.critic_value = torch.sum(multiply, dim = 1)\n",
    "        self.final_critic_value = self.critic_value + self.enn_out\n",
    "        return self.final_critic_value\n",
    "\n",
    "\n",
    "    def predict_gmm_params(self, observation):\n",
    "        #current and next observation through networks with same z_dim as above\n",
    "        base_in = self.base_in(observation)\n",
    "        base_1 = self.base_1(base_in).to(self.device)\n",
    "        base_out = self.base_out(base_1)\n",
    "\n",
    "        means = base_out[:, :self.num_gaussians]\n",
    "        sigmas_prev = base_out[:, self.num_gaussians:self.num_gaussians*2]\n",
    "        sigmas = self.elu(sigmas_prev) + self.adder\n",
    "        alphas = base_out[:, self.num_gaussians*2:]\n",
    "        \n",
    "        return means, sigmas, alphas\n",
    "    \n",
    "    def compute_log_likelihood(self, td_targets, mu_pred, sigma_pred, alphas_pred):\n",
    "        \n",
    "        td_targets_expanded = td_targets.unsqueeze(1)\n",
    "        \n",
    "        sigma_clamped = torch.clamp(sigma_pred, 1e-7, None)\n",
    "        denominator = (2*torch.square(sigma_clamped)).clamp_min(1e-7)\n",
    "        # alphas_clamped = torch.clamp(alpha_pred, 1e-30, 1e5)\n",
    "        \n",
    "        log_2_pi = torch.log(2*torch.tensor(math.pi))\n",
    "        \n",
    "        mus = td_targets_expanded - mu_pred\n",
    "        alphas = alphas_pred.clamp_min(1e-7)\n",
    "        \n",
    "        logp = (-torch.log(sigma_clamped) - .5 * log_2_pi - torch.square(mus)) / denominator\n",
    "        loga = torch.nn.functional.log_softmax(alphas, dim=-1)\n",
    "\n",
    "        summing_log = -torch.logsumexp(logp + loga, dim=-1)\n",
    "        \n",
    "        return summing_log \n",
    "        \n",
    "    def enn_loss(self, next_obs, rewards, dones):\n",
    "        #base target value        \n",
    "        next_base_in = self.base_in(next_obs)\n",
    "        next_base_1 = self.base_1(next_base_in)\n",
    "        next_base_1_detached_unsqueeze = torch.unsqueeze(next_base_1, 1).detach()\n",
    "        next_base_out = self.base_out(next_base_1).detach()\n",
    "    \n",
    "        #enn target value\n",
    "        next_enn_input = torch.cat((self.z_unsqueeze, next_base_1_detached_unsqueeze.expand(-1, self.z_dim, -1)), dim=2)\n",
    "        next_learnable_in = self.enn_learnable_in(next_enn_input)\n",
    "        next_learnable_1 = self.enn_learnable_1(next_learnable_in)\n",
    "        next_learnable = self.enn_learnable_out(next_learnable_1)\n",
    "        next_learnable_bmm = torch.bmm(torch.transpose(next_learnable, 1, 2), self.z_unsqueeze)\n",
    "        next_learnable_out = next_learnable_bmm.squeeze(-1)\n",
    "    \n",
    "        if self.step_number < self.step_cut_off:\n",
    "            #prior target value (learnable)\n",
    "            next_prior_in = self.prior_in(next_enn_input)\n",
    "            next_prior_1 = self.prior_1(next_prior_in)\n",
    "            next_prior = self.prior_out(next_prior_1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #prior target value (static)\n",
    "                next_prior_in = self.prior_in(next_enn_input)\n",
    "                next_prior_1 = self.prior_1(next_prior_in)\n",
    "                next_prior = self.prior_out(next_prior_1)\n",
    "    \n",
    "        next_prior_bmm = torch.bmm(torch.transpose(next_prior, 1, 2), self.z_unsqueeze)\n",
    "        next_prior_out = next_prior_bmm.squeeze(-1)\n",
    "    \n",
    "        # add all networks together to get final action values\n",
    "        means = next_base_out[:, :self.num_gaussians]\n",
    "        sigmas_prev = next_base_out[:, self.num_gaussians:self.num_gaussians*2]\n",
    "        sigmas = self.elu(sigmas_prev) + self.adder\n",
    "        alphas = next_base_out[:, self.num_gaussians*2:]\n",
    "        # get the weighted average plus the ENN output as in the forward pass\n",
    "        self.enn_target = torch.mean(next_learnable_out + next_prior_out, dim = -1)\n",
    "        # again, I think I have to take the mean above to get a tensor of batch size rather than a single scalar output over the batch (previously summed)\n",
    "        next_values = torch.sum(means * alphas, dim = -1) + self.enn_target\n",
    "\n",
    "        # make up the TD target for the ENN\n",
    "        enn_target = rewards + self.gamma * next_values.clone().detach() * (1 - dones.float())\n",
    "        enn_loss_square = torch.square(self.final_critic_value - enn_target)\n",
    "        enn_loss = torch.mean(enn_loss_square)\n",
    "        \n",
    "        return enn_loss\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def custom_loss(self, policy_loss, sample_batch):\n",
    "\n",
    "        cur_obs = sample_batch[SampleBatch.CUR_OBS]\n",
    "        next_states = sample_batch[SampleBatch.NEXT_OBS]\n",
    "        rewards = sample_batch[SampleBatch.REWARDS]\n",
    "        dones = sample_batch[SampleBatch.DONES]\n",
    "\n",
    "        enn_loss = self.enn_loss(next_states, rewards, dones)\n",
    "\n",
    "        mu_pred, sigma_pred, w_pred = self.predict_gmm_params(cur_obs)\n",
    "        mu_target, sigma_target, w_target = self.predict_gmm_params(next_states)\n",
    "        # only the target alphas go through softmax since predicted alphas go through log softmax later\n",
    "        w_target = torch.nn.functional.softmax(w_target, dim = -1)\n",
    "\n",
    "        next_state_value = torch.sum(mu_target * w_target, dim = 1)\n",
    "        td_targets = rewards + self.gamma * next_state_value.detach() * (1 - dones.float())\n",
    "        \n",
    "        log_likelihood = self.compute_log_likelihood(td_targets, mu_pred, sigma_pred, w_pred)\n",
    "        log_likelihood = torch.clamp(log_likelihood, -10, 80)\n",
    "        nll_loss = torch.mean(log_likelihood)\n",
    "\n",
    "        if self.step_number % 1_000 == 0:\n",
    "            print(f\"policy loss: {policy_loss} enn loss: {enn_loss} nll loss: {nll_loss}\")\n",
    "        \n",
    "        total_loss = [loss + (nll_loss + enn_loss) for loss in policy_loss]\n",
    "        \n",
    "        return total_loss        \n",
    "\n",
    "\n",
    "# Register the custom model to make it available to Ray/RLlib\n",
    "ModelCatalog.register_custom_model(\"NLL_ENNModel\", NLL_EpistemicNNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa909d6-573e-4ac9-b042-754a86bc1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpistemicNNModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super(EpistemicNNModel, self).__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "        #get layers from config\n",
    "        hidden_layer0 = model_config['fcnet_hiddens'][0]\n",
    "        hidden_layer1 = model_config['fcnet_hiddens'][1]\n",
    "        enn_layer = 50\n",
    "        #object instance variables\n",
    "        self.std = 1.0\n",
    "        # self.seed = 15546\n",
    "        self.mean = 0.0\n",
    "        self.gamma = 0.99\n",
    "        self.step_number = 0\n",
    "        self.z_indices = None\n",
    "        # random.seed(self.seed)\n",
    "        # np.random.seed(self.seed)\n",
    "        self.action_space_size = 4\n",
    "        # torch.manual_seed(self.seed)\n",
    "        self.num_actions = action_space.shape[0]\n",
    "        self.initializer = torch.nn.init.xavier_normal_\n",
    "        self.initializer_old = torch.nn.init.kaiming_normal_\n",
    "        self.activation_fn = model_config['fcnet_activation']\n",
    "        self.z_dim = model_config['custom_model_config'].get('z_dim', 5)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.distribution = Normal(torch.full((self.z_dim,), self.mean), torch.full((self.z_dim,), self.std))\n",
    "        #build main actor/critic networks\n",
    "        # self.critic_network = TorchFC(obs_space, action_space, 1, model_config, name + \"_q_testing\")\n",
    "        self.actor_network = TorchFC(obs_space, action_space, action_space.shape[0]*2, model_config, name + \"_q_testing\")\n",
    "        self.base_in = SlimFC(obs_space.shape[0], hidden_layer0, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.base_1 = SlimFC(hidden_layer0, hidden_layer1, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.base_out = SlimFC(hidden_layer1, 1, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        #enn learnable network\n",
    "        self.enn_learnable_in = SlimFC(hidden_layer1 + 1, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.enn_learnable_1 = SlimFC(enn_layer, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.enn_learnable_out = SlimFC(enn_layer, 1, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        #prior network (learnable for x steps and then static afterwards)\n",
    "        self.prior_in = SlimFC(hidden_layer1 + 1, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.prior_1 = SlimFC(enn_layer, enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.prior_out = SlimFC(enn_layer, 1, initializer=self.initializer, activation_fn=self.activation_fn)        \n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict[\"obs_flat\"].float()        \n",
    "        action_logits, _ = self.actor_network(input_dict, state, seq_lens)\n",
    "        batch_size = obs.shape[0]\n",
    "\n",
    "        base_in = self.base_in(obs)\n",
    "        base_1 = self.base_1(base_in).to(self.device)\n",
    "        base_1_detach_enn = torch.unsqueeze(base_1, 1).clone().detach()\n",
    "        base_out = self.base_out(base_1).detach()\n",
    "\n",
    "        self.z_indices = self.distribution.sample((batch_size,)).to(self.device)\n",
    "        self.z_unsqueeze = torch.unsqueeze(self.z_indices, -1)\n",
    "        enn_input = torch.cat((self.z_unsqueeze, base_1_detach_enn.expand(-1, self.z_dim, -1)), dim=2)\n",
    "\n",
    "        if self.step_number < 200:\n",
    "            #prior value (learnable)\n",
    "            prior_in = self.prior_in(enn_input)\n",
    "            prior_1 = self.prior_1(prior_in)\n",
    "            prior = self.prior_out(prior_1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #prior value (static)\n",
    "                prior_in = self.prior_in(enn_input)\n",
    "                prior_1 = self.prior_1(prior_in)\n",
    "                prior = self.prior_out(prior_1)\n",
    "                \n",
    "        prior_bmm = torch.bmm(torch.transpose(prior, 1, 2), self.z_unsqueeze)\n",
    "        prior_output = prior_bmm.squeeze(-1)\n",
    "        # learnable on features and z concat\n",
    "        learnable_in = self.enn_learnable_in(enn_input)\n",
    "        learnable_1 = self.enn_learnable_1(learnable_in)\n",
    "        learnable = self.enn_learnable_out(learnable_1)\n",
    "        learnable_bmm = torch.bmm(torch.transpose(learnable, 1, 2), self.z_unsqueeze)\n",
    "        learnable_out = learnable_bmm.squeeze(-1)\n",
    "\n",
    "        # add all networks together to get final action values\n",
    "        self.critic_value = base_out + learnable_out + prior_output\n",
    "\n",
    "        self.step_number += 1\n",
    "            \n",
    "            \n",
    "        return action_logits, state\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        return self.critic_value.squeeze(-1)\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def custom_loss(self, policy_loss, sample_batch):\n",
    "\n",
    "        cur_obs = sample_batch[SampleBatch.CUR_OBS]\n",
    "        next_obs = sample_batch[SampleBatch.NEXT_OBS]\n",
    "        rewards = sample_batch[SampleBatch.REWARDS]\n",
    "        dones = sample_batch[SampleBatch.DONES]\n",
    "\n",
    "        #base target value\n",
    "        next_base_in = self.base_in(next_obs)\n",
    "        next_base_1 = self.base_1(next_base_in)\n",
    "        next_base_1_detached_unsqueeze = torch.unsqueeze(next_base_1, 1).detach()\n",
    "        next_base_out = self.base_out(next_base_1).detach()\n",
    "\n",
    "        #enn target value\n",
    "        next_enn_input = torch.cat((self.z_unsqueeze, next_base_1_detached_unsqueeze.expand(-1, self.z_dim, -1)), dim=2)\n",
    "        next_learnable_in = self.enn_learnable_in(next_enn_input)\n",
    "        next_learnable_1 = self.enn_learnable_1(next_learnable_in)\n",
    "        next_learnable = self.enn_learnable_out(next_learnable_1)\n",
    "        next_learnable_bmm = torch.bmm(torch.transpose(next_learnable, 1, 2), self.z_unsqueeze)\n",
    "        next_learnable_out = next_learnable_bmm.squeeze(-1)\n",
    "\n",
    "        if self.step_number < 200:\n",
    "            #prior target value (learnable)\n",
    "            next_prior_in = self.prior_in(next_enn_input)\n",
    "            next_prior_1 = self.prior_1(next_prior_in)\n",
    "            next_prior = self.prior_out(next_prior_1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #prior target value (static)\n",
    "                next_prior_in = self.prior_in(next_enn_input)\n",
    "                next_prior_1 = self.prior_1(next_prior_in)\n",
    "                next_prior = self.prior_out(next_prior_1)\n",
    "\n",
    "        next_prior_bmm = torch.bmm(torch.transpose(next_prior, 1, 2), self.z_unsqueeze)\n",
    "        next_prior_out = next_prior_bmm.squeeze(-1)\n",
    "\n",
    "        # add all networks together to get final action values\n",
    "        next_values = next_base_out + next_learnable_out + next_prior_out\n",
    "        enn_target = rewards + self.gamma * next_values.detach() * (1 - dones.float())\n",
    "        enn_loss_square = torch.square(self.critic_value - enn_target)\n",
    "        enn_loss = torch.mean(enn_loss_square)\n",
    "\n",
    "        total_loss = [loss + enn_loss for loss in policy_loss]\n",
    "\n",
    "        if self.step_number % 1_000 == 0:\n",
    "            print(f\"policy loss: {policy_loss} enn loss: {enn_loss}\")\n",
    "        \n",
    "        return total_loss        \n",
    "\n",
    "\n",
    "# Register the custom model to make it available to Ray/RLlib\n",
    "ModelCatalog.register_custom_model(\"ENNModel\", EpistemicNNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012a191-ffaa-4a6d-92d1-f1b5713e0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### %%time\n",
    "config = PPOConfig().training(\n",
    "    gamma = 0.99,\n",
    "    lambda_ = 0.95,\n",
    "    num_sgd_iter = 30,\n",
    "    lr_schedule = [[0, 0.0003], [15_000_000, 0.00025], [25_000_000, 0.0002], [30_000_000, 0.0001]],\n",
    "    # lr = 0.001,\n",
    "    vf_loss_coeff = 1.0,\n",
    "    vf_clip_param = 15.0,\n",
    "    clip_param = 0.3,\n",
    "    grad_clip_by = 'norm', \n",
    "    train_batch_size = 65_500, \n",
    "    sgd_minibatch_size = 12_500,\n",
    "    grad_clip = 1.0,\n",
    "    # optimizer = {\n",
    "    #     'weight_decay': 0.01\n",
    "    # },\n",
    "    model={\n",
    "        'custom_model': 'NLL_ENNModel', #ENNModel NLL_ENNModel\n",
    "        'fcnet_hiddens': [512, 512],\n",
    "        'fcnet_activation': 'LeakyReLU',\n",
    "        'vf_share_layers': False,\n",
    "        'custom_model_config': {\n",
    "            'z_dim': 5,\n",
    "            'num_gaussians': 3,\n",
    "        },\n",
    "    }\n",
    ").environment(env='HalfCheetah-v4'\n",
    ").rollouts(\n",
    "num_rollout_workers = 28,\n",
    "# num_envs_per_worker = 4,\n",
    ").resources(num_gpus = 1)\n",
    "#.callbacks(MyCustomCallback\n",
    "#)\n",
    "algo = config.build()\n",
    "\n",
    "num_iterations = 200\n",
    "rewards = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    result = algo.train()\n",
    "    print(f\"Iteration: {i}, Mean Reward: {result['episode_reward_mean']}\")\n",
    "    rewards.append(result['episode_reward_mean'])\n",
    "    \n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4b7b0-e7c9-453a-8293-686cf7b789cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_weights = algo.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c0cc5-7d0c-45c6-8110-c0693a8716f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_weight_keys = [key for key in policy_weights['default_policy'] if 'prior' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e811955-ccac-4263-be84-397e8bb025bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_weights = {key: policy_weights['default_policy'][key] for key in prior_weight_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3279c0-c340-410c-a230-72be3136428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_weights['prior_1._model.0.weight'][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
