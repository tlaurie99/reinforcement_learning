{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6d410-4dab-451c-a904-7f64b15fce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray import tune, air\n",
    "from ray.rllib.core.models.configs import MLPHeadConfig\n",
    "from ray.rllib.core.models.catalog import Catalog\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.annotations import OverrideToImplementCustomLogic\n",
    "from gymnasium.spaces import Box\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig\n",
    "import ray.rllib.algorithms.ppo as ppo\n",
    "from ray.rllib.utils.typing import Dict, TensorType, List, ModelConfigDict\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from ray.rllib.models.torch.misc import SlimFC, AppendBiasLayer\n",
    "from ray.rllib.policy.torch_policy import TorchPolicy\n",
    "from ray.rllib.policy.policy_template import build_policy_class\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.utils.annotations import override\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ray import tune\n",
    "import math\n",
    "from torch.distributions.normal import Normal\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import os \n",
    "import shutil\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c731a0-994d-4ffe-a802-402036ac4228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch, nn = try_import_torch()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa909d6-573e-4ac9-b042-754a86bc1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpistemicNNModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super(EpistemicNNModel, self).__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        \n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.mean = 0.0\n",
    "        self.std = 1.0\n",
    "        self.z_dim = 10\n",
    "        self.critic_output_dims = model_config['fcnet_hiddens'][-1]\n",
    "        self.actor_output_dims = model_config['fcnet_hiddens'][-1]\n",
    "        self.initializer = torch.nn.init.xavier_normal_\n",
    "        self.activation_fn = model_config['fcnet_activation']\n",
    "        self.enn_layer = 50\n",
    "        self.action_outputs = action_space.shape[0]*2\n",
    "        self.step_number = 0\n",
    "        self.z_indices = None\n",
    "        self.obs_space = obs_space\n",
    "        self.action_space = action_space\n",
    "        self.gamma = 0.99\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.distribution = Normal(torch.full((self.z_dim,), self.mean), torch.full((self.z_dim,), self.std))\n",
    "\n",
    "        self.actor = TorchFC(obs_space, action_space, action_space.shape[0]*2, model_config, name + \"_actor\")\n",
    "\n",
    "        self.critic_in = SlimFC(obs_space.shape[0], model_config['fcnet_hiddens'][0], initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.critic_1 = SlimFC(model_config['fcnet_hiddens'][0], self.critic_output_dims, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.critic_out = SlimFC(self.critic_output_dims, 1, initializer=self.initializer, activation_fn=None)\n",
    "        \n",
    "        self.enn_learnable_1 = SlimFC(self.critic_output_dims + self.z_dim, self.enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.enn_learnable_out = SlimFC(self.enn_layer, self.z_dim*1, initializer=self.initializer, activation_fn=None)\n",
    "\n",
    "        self.prior_1 = SlimFC(self.critic_output_dims + self.z_dim, self.enn_layer, initializer=self.initializer, activation_fn=self.activation_fn)\n",
    "        self.prior_out = SlimFC(self.enn_layer, self.z_dim*1, initializer=self.initializer, activation_fn=None)\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        action_logits, _ = self.actor(input_dict, state, seq_lens)\n",
    "        # action_logits_out = self.actor_out(action_logits)\n",
    "        batch_size = action_logits.shape[0]\n",
    "\n",
    "        self.z_indices = self.distribution.sample((batch_size,)).to(self.device)\n",
    "\n",
    "        obs = input_dict[\"obs_flat\"].float()\n",
    "        \n",
    "        self.step_number += 1\n",
    "        if self.step_number < 50:\n",
    "            #this step counter will count with the dummy loss initialization as well\n",
    "            critic_0 = self.critic_in(obs)\n",
    "            critic_features = self.critic_1(critic_0)\n",
    "            self.critic_out_value = self.critic_out(critic_features)\n",
    "            critic_features_detached = critic_features.detach()\n",
    "            z_concat = torch.cat((critic_features_detached, self.z_indices), 1)\n",
    "\n",
    "            #make passes through ENN and prior to allow params / gradients to be initialzed in the ENN & prior networks\n",
    "            enn_layer_1_out = self.enn_learnable_1(z_concat)\n",
    "            enn_layer = self.enn_learnable_out(enn_layer_1_out)\n",
    "            enn_layer_unsqeeze_out = torch.unsqueeze(enn_layer, -1)\n",
    "            z_unsqueeze = torch.unsqueeze(self.z_indices, -1)\n",
    "            enn_layer_bmm = torch.bmm(torch.transpose(enn_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "            enn_layer_out = enn_layer_bmm.squeeze(-1)\n",
    "            \n",
    "    \n",
    "            prior_layer_1 = self.prior_1(z_concat)\n",
    "            prior_layer = self.prior_out(prior_layer_1)\n",
    "            prior_layer_unsqeeze_out = torch.unsqueeze(prior_layer, -1)\n",
    "            prior_layer_bmm = torch.bmm(torch.transpose(prior_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "            prior_layer_out = prior_layer_bmm.squeeze(-1)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            #process critic output\n",
    "            critic_0 = self.critic_in(obs)\n",
    "            critic_features = self.critic_1(critic_0)\n",
    "            value_out = self.critic_out(critic_features)\n",
    "            critic_features_detached = critic_features.detach()\n",
    "            z_concat = torch.cat((critic_features_detached, self.z_indices), 1)\n",
    "\n",
    "            #make passes through ENN and prior\n",
    "            enn_layer_1_out = self.enn_learnable_1(z_concat)\n",
    "            enn_layer = self.enn_learnable_out(enn_layer_1_out)\n",
    "            enn_layer_unsqeeze_out = torch.unsqueeze(enn_layer, -1)\n",
    "            z_unsqueeze = torch.unsqueeze(self.z_indices, -1)\n",
    "            enn_layer_bmm = torch.bmm(torch.transpose(enn_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "            enn_layer_out = enn_layer_bmm.squeeze(-1)\n",
    "\n",
    "            #after capturing initial uncertainty pass features / z through the prior without learning to maintain this initial uncertainty\n",
    "            with torch.no_grad():\n",
    "                prior_layer_1 = self.prior_1(z_concat)\n",
    "                prior_layer = self.prior_out(prior_layer_1)\n",
    "                prior_layer_unsqeeze_out = torch.unsqueeze(prior_layer, -1)\n",
    "                prior_layer_bmm = torch.bmm(torch.transpose(prior_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "                prior_layer_out = prior_layer_bmm.squeeze(-1)\n",
    "    \n",
    "            # #add prior and ENN to the value network out\n",
    "            self.critic_out_value = value_out + enn_layer_out + prior_layer_out\n",
    "            \n",
    "        return action_logits, state\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        #for the first 10 steps use the base network as the summed value\n",
    "        #then return the value = base_value + enn layer out  + prior layer out\n",
    "        return self.critic_out_value.squeeze(-1)\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def custom_loss(self, policy_loss, sample_batch):\n",
    "\n",
    "        cur_obs = sample_batch[SampleBatch.CUR_OBS]\n",
    "        next_obs = sample_batch[SampleBatch.NEXT_OBS]\n",
    "        rewards = sample_batch[SampleBatch.REWARDS]\n",
    "        dones = sample_batch[SampleBatch.DONES]\n",
    "\n",
    "\n",
    "        critic_0 = self.critic_in(cur_obs)\n",
    "        critic_features = self.critic_1(critic_0)\n",
    "        value_out = self.critic_out(critic_features)\n",
    "        \n",
    "        critic_features_detached = critic_features.detach()\n",
    "        z_concat = torch.cat((critic_features_detached, self.z_indices), 1)\n",
    "        enn_layer_1_out = self.enn_learnable_1(z_concat)\n",
    "        enn_layer = self.enn_learnable_out(enn_layer_1_out)\n",
    "        enn_layer_unsqeeze_out = torch.unsqueeze(enn_layer, -1)\n",
    "        z_unsqueeze = torch.unsqueeze(self.z_indices, -1)\n",
    "        enn_layer_bmm = torch.bmm(torch.transpose(enn_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "        enn_layer_out = enn_layer_bmm.squeeze(-1)\n",
    "\n",
    "        prior_layer_1 = self.prior_1(z_concat)\n",
    "        prior_layer = self.prior_out(prior_layer_1)\n",
    "        prior_layer_unsqeeze_out = torch.unsqueeze(prior_layer, -1)\n",
    "        prior_layer_bmm = torch.bmm(torch.transpose(prior_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "        prior_layer_out = prior_layer_bmm.squeeze(-1)\n",
    "        \n",
    "        next_critic_0 = self.critic_in(next_obs)\n",
    "        next_critic_features = self.critic_1(next_critic_0)\n",
    "        next_critic_features_detached = next_critic_features.detach()\n",
    "        next_z_concat = torch.cat((next_critic_features_detached, self.z_indices), 1)\n",
    "        enn_layer_1_out = self.enn_learnable_1(next_z_concat)\n",
    "        enn_layer = self.enn_learnable_out(enn_layer_1_out)\n",
    "        enn_layer_unsqeeze_out = torch.unsqueeze(enn_layer, -1)\n",
    "        z_unsqueeze = torch.unsqueeze(self.z_indices, -1)\n",
    "        enn_layer_bmm = torch.bmm(torch.transpose(enn_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "        enn_layer_out_next = enn_layer_bmm.squeeze(-1)\n",
    "\n",
    "        next_critic_value_out = self.critic_out(next_critic_features)\n",
    "\n",
    "        next_prior_layer_1 = self.prior_1(next_z_concat)\n",
    "        next_prior_layer = self.prior_out(next_prior_layer_1)\n",
    "        next_prior_layer_unsqeeze_out = torch.unsqueeze(next_prior_layer, -1)\n",
    "        next_prior_layer_bmm = torch.bmm(torch.transpose(next_prior_layer_unsqeeze_out, 1, 2), z_unsqueeze)\n",
    "        next_prior_layer_out = next_prior_layer_bmm.squeeze(-1)\n",
    "        #enn network TD loss\n",
    "        enn_out = enn_layer_out + prior_layer_out\n",
    "        next_enn_out = enn_layer_out_next + next_prior_layer_out\n",
    "\n",
    "        #should the prior network be in this loss to updates params for the first xx steps??\n",
    "        td_target = rewards + self.gamma * next_enn_out * (1 - dones.float())\n",
    "\n",
    "        td_loss_square = torch.square(enn_out - td_target)\n",
    "        td_loss = torch.mean(td_loss_square)\n",
    "        #critic base network TD loss\n",
    "        td_target_base = rewards + self.gamma * next_critic_value_out * (1 - dones.float())\n",
    "        td_base_square = torch.square(value_out - td_target_base)\n",
    "        td_base_loss = torch.mean(td_base_square)\n",
    "\n",
    "        total_loss = sum(policy_loss) + td_loss + td_base_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "    # @override(TorchModelV2)\n",
    "    # can't do this within a model class -- happens within the policy object\n",
    "    # def optimizer(self):\n",
    "    #     params_with_decay = []\n",
    "    #     params_without_decay = []\n",
    "    #     for name, param in self.named_parameters():\n",
    "    #         if \"enn\" in name:\n",
    "    #             params_with_decay.append(param)\n",
    "    #         else:\n",
    "    #             params_without_decay.append(param)\n",
    "    #     return optim.Adam([\n",
    "    #         {'params': params_with_decay, 'weight_decay': 0.01},\n",
    "    #         #this will add L2 regularization only for the \"enn\" part of the gradient graph\n",
    "    #         {'params': params_without_decay, 'weight_decay': 0},\n",
    "    #     ])\n",
    "        \n",
    "\n",
    "\n",
    "# Register the custom model to make it available to Ray/RLlib\n",
    "ModelCatalog.register_custom_model(\"ENNModel\", EpistemicNNModel)\n",
    "\n",
    "\n",
    "''' FIXES\n",
    "-Changed how the prior network functioned by implementing an if statement under 10 steps\n",
    "--This ensures that the stop gradient is used after step 10 to encapsulate the \"uncertainty\" of pre-training\n",
    "-Fixed the learnable ENN dimensions to output (Dz X C).T * Dz(vector)\n",
    "-Add loss function from page 4 in \"Approximate Thompson Sampling via Epistemic Neural Networks\" (quadractic TD loss)\n",
    "-Had to break down the critic branch to be multiple SlimFC's due to needing it in the custom loss where we do not have access to input_dict\n",
    "-Updated the draw from the Pz distribution to not inidate a new distribution every forward pass\n",
    "--i.e. create a Pz in the beginning and draw from the same one throughout training\n",
    "-Added the prior function to the loss function to encapsulate all of the ENN\n",
    "-Added L2 regularization (weight_decay for the optimizer step for the ENN network only)\n",
    "-Fixed prior network ENN to output correct dimensions (Dz X C).T * Dz(vector) like the ENN learnable in forward and loss function (including \"next\")\n",
    "-Critic output to have no activation (changed from self.activation_fn --> None)\n",
    "-Detach the features from the epinet's gradient map\n",
    "-Added base network TD loss to custom loss\n",
    "\n",
    "\n",
    "OBSERVATIONS:\n",
    "-The first trial seemed to work the best so far -- this had no loss function, incorrect dim outputs (only hiddens[-1] x 1)\n",
    "-Training became exponentially slow while adding the loss function\n",
    "\n",
    "\n",
    "THOUGHTS:\n",
    "-Should I only do weight_decay for the ENN and not over all networks? answer: just the ENN learnable\n",
    "-Are the dimensions logical for the step (Dz X C).T * Dz(vector)?     answer: yes -- this is correct where C is the mean value (or it could be the MoGs)\n",
    "-What slowed down computation so much while adding the loss?          answer: (maybe) -- I had the ENN networks backpropagating into the base network\n",
    "-Check over the loss function                                         answer: checked and correct per page 4 within ARXIV: 2302.09205 TD loss for RL\n",
    "-\"we optimize L through SGD -- at each gradient step we sample a mini-batch of data D and a batch of indices Z from Pz and we take a gradient step wrt the quadratic TD loss\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d1c38-0f76-4bbd-93b0-34ef49584e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig().training(\n",
    "    gamma = 0.99,\n",
    "    lambda_ = 0.95,\n",
    "    # kl_coeff = 1.0,\n",
    "    num_sgd_iter = 30,\n",
    "    lr_schedule = [[0, 0.0003], [5_000_000, 0.00025], [15_000_000, 0.00020], [30_000_000, 0.00015]],\n",
    "    vf_loss_coeff = 1.0,\n",
    "    #reintroduced clip param\n",
    "    vf_clip_param = 15.0,\n",
    "    clip_param = 0.3,\n",
    "    grad_clip_by = 'norm', \n",
    "    train_batch_size = 65_500, \n",
    "    sgd_minibatch_size = 4_096,\n",
    "    grad_clip = 1.0,\n",
    "    model={\n",
    "        'custom_model': 'ENNModel',\n",
    "        'fcnet_hiddens': [512, 512],\n",
    "        'fcnet_activation': 'LeakyReLU'\n",
    "    }\n",
    ").environment(env='HalfCheetah-v4'\n",
    ").rollouts(\n",
    "num_rollout_workers = 28,\n",
    "# num_envs_per_worker = 4,\n",
    ")\n",
    "#.callbacks(MyCustomCallback\n",
    "#)\n",
    "algo = config.build()\n",
    "\n",
    "num_iterations = 400\n",
    "rewards = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    result = algo.train()\n",
    "    print(f\"Iteration: {i}, Mean Reward: {result['episode_reward_mean']}\")\n",
    "    rewards.append(result['episode_reward_mean'])\n",
    "    \n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4b7b0-e7c9-453a-8293-686cf7b789cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_weights = algo.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c0cc5-7d0c-45c6-8110-c0693a8716f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_weight_keys = [key for key in policy_weights['default_policy'] if 'prior' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e811955-ccac-4263-be84-397e8bb025bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_weights = {key: policy_weights['default_policy'][key] for key in prior_weight_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3279c0-c340-410c-a230-72be3136428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_weights['prior_1._model.0.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74eb3f-68d3-408f-8649-3c94c6632477",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_dim_change = pd.DataFrame(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349485c7-1826-4779-a964-e639a1e3ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_dim_change.to_csv(path + '/dim_change.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5133803-79b9-4a7d-bba6-7a92034e4da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
