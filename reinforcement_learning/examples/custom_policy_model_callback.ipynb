{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import ray\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ray import tune\n",
    "from ppo_torch_policy import SimpleTorchPolicy\n",
    "from ray.rllib.algorithms.ppo import PPOConfig, PPO\n",
    "from SimpleTorchModel import SimpleCustomTorchModel\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from normalize_advantages import NormalizeAdvantagesCallback\n",
    "\n",
    "from ray.tune.tune_config import TuneConfig\n",
    "from ray.tune.tuner import Tuner\n",
    "from ray.air.config import ScalingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8aeef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "torch, nn = try_import_torch()\n",
    "ray.init(num_cpus = 32, num_gpus = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1748fa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# NOTE: this env does not support multi-agent so it doesn't run\n",
    "# this was used as only a base example of how to run such a policy, model, and callback\n",
    "env_name = 'HalfCheetah-v4'\n",
    "env = gym.make(env_name)\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "\n",
    "config = PPOConfig().training(\n",
    "    gamma = 0.99,\n",
    "    lambda_ = 0.95,\n",
    "    # kl_coeff = 0.5,\n",
    "    num_sgd_iter = 30,\n",
    "    lr_schedule = [[0, 0.0003], [15_000_000, 0.00025], [30_000_000, 0.0002], [50_000_000, 0.0001]],\n",
    "    vf_loss_coeff = 0.5,\n",
    "    vf_clip_param = 15.0,\n",
    "    clip_param = 0.2,\n",
    "    grad_clip_by ='norm', \n",
    "    train_batch_size = 65_000, \n",
    "    sgd_minibatch_size = 4_096,\n",
    "    grad_clip = 0.5,\n",
    "    model = {'custom_model': 'SimpleCustomTorchModel', \n",
    "           'vf_share_layers': False,\n",
    "           'fcnet_hiddens': [256,256],\n",
    "           'fcnet_activation': 'LeakyReLU',\n",
    "             #this isn't used for some models, but doesn't hurt to keep it\n",
    "           'custom_model_config': {\n",
    "                'num_gaussians': 2,\n",
    "               'num_outputs': action_space.shape[0]\n",
    "           }\n",
    "            }\n",
    ").environment(env = env_name\n",
    ").rollouts(\n",
    "num_rollout_workers = 28\n",
    ").resources(num_gpus = 1\n",
    ").callbacks(NormalizeAdvantagesCallback\n",
    ").multi_agent(\n",
    "    policies = {\n",
    "        'policy_1': (SimpleTorchPolicy, obs_space, action_space, {}),\n",
    "    },\n",
    "    policy_mapping_fn = lambda agent_id: 'policy_1' if agent_id % 2 == 0 else 'policy_2'\n",
    ")\n",
    "\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "# config['policy'] = SimpleTorchPolicy\n",
    "\n",
    "analysis = tune.run(\n",
    "    \"PPO\",\n",
    "    config=config.to_dict(),\n",
    "    stop={\"training_iteration\": 1},\n",
    "    checkpoint_freq=10,\n",
    "    checkpoint_at_end=True,\n",
    "    local_dir=\"./ray_results\", \n",
    ")\n",
    "\n",
    "num_iterations = 1\n",
    "results = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    result = analysis.results_df\n",
    "    mean_reward = result['episode_reward_mean'].iloc[-1]\n",
    "    mean_length = result['episode_len_mean'].iloc[-1]\n",
    "    print(f\"Iteration: {i}, Mean Reward: {mean_reward}\")\n",
    "    results.append([mean_reward, mean_length])\n",
    "\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "    \n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9307821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
